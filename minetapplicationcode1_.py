# -*- coding: utf-8 -*-
"""MINetApplicationCode1_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MRjoB9RA6pWlt12uToY9t6cKGbKxqNiU

# **App - Streamlit + Pycaret**
"""

import pycaret
from pycaret.regression import load_model, predict_model
import streamlit as st
import nltk
nltk.download('punkt')

from pycaret.classification import load_model
model = load_model('knn7')

def predict(model, input_df):
  predictions_df = predict_model(estimator=model, data=input_df)
  predictions = predictions_df['Label'][0]
  return predictions

def run():
  from PIL import Image
  image = Image.open('minetlogo.JPG')
  st.image(image, use_column_width = False)
  st.sidebar.info('MINet: A Novel Telemedicine Tool for Automagtically Assessing Motivational Interviewing (MI) Conversations Using Natural Language Processing')

import contractions

file_upload = st.file_uploader('Upload Transcript for Rating +  Feedback. Ensure they are in PDF/TXT form and the counselor and patient portions are indicated with "c:" and "p:" at the beginning of every line.', type=["txt","pdf"])
if file_upload is not None:
  file_contents2 = file_upload.read()
  fu = str(file_contents2)
  ru = contractions.fix(fu)
  yu = ru.lower()

  # preprocessing
  import nltk
  nltk.download('stopwords')
  from nltk.tokenize import word_tokenize  
  stopwords = nltk.corpus.stopwords.words('english')
  removed = ['c', ':', 't', '.', '?', '!', ',']
  stopwords.extend(removed)

  z = nltk.word_tokenize(yu)
  z2 = [word for word in z if word not in stopwords]

  nltk.download('wordnet')
  from nltk.corpus import wordnet
  nltk.download('averaged_perceptron_tagger')

  def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ,
                "N": wordnet.NOUN,
                "V": wordnet.VERB,
                "R": wordnet.ADV}

    return tag_dict.get(tag, wordnet.NOUN)
  from nltk.stem import WordNetLemmatizer

  lemmatizer = WordNetLemmatizer()
  for word in z2:
    qu = ((lemmatizer.lemmatize(word, get_wordnet_pos(word))))

  # word length
  wordcount3 = len(yu.split())


  if st.button("Predict"):
    print (wordcount3)
    
